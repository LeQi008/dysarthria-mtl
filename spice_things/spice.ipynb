{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ec6779",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c71ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TFWav2Vec2Model has backpropagation operations that are NOT supported on CPU. If you wish to train/fine-tune this model, you need a GPU or a TPU\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFWav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFWav2Vec2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFWav2Vec2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFWav2Vec2Model were not initialized from the PyTorch model and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Error processing audio 16_speaker 1 sev_segment 1 chunk 1 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 1 chunk 1.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 1 chunk 2 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 1 chunk 2.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 1 chunk 3 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 1 chunk 3.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 2 chunk 1 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 2 chunk 1.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 2 chunk 2 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 2 chunk 2.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 2 chunk 3 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 2 chunk 3.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 2 chunk 4 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 2 chunk 4.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "[!] Error processing audio 16_speaker 1 sev_segment 2 chunk 5 at E:\\labelled_speech\\YouTube Audio\\dysarthric speech\\audio 16\\speaker 1 sev\\segment 2 chunk 5.wav: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File c:\\Users\\YIDAN\\Desktop\\projects\\dysarthria-mtl-steal\\venvspice\\lib\\site-packages\\librosa\\core\\audio.py, line 33, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n",
      "\n",
      "✅ Done! Results saved to: ./spice_results_youtube_noiseReduce.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import scipy.io.wavfile as wav\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from transformers import Wav2Vec2Processor, TFWav2Vec2Model\n",
    "\n",
    "# Load models\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "hf_w2v2_model = TFWav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "spice_w2v2_cls_model = hub.KerasLayer('https://tfhub.dev/google/euphonia_spice/classification/1')\n",
    "\n",
    "# Ensure 16kHz sample rate\n",
    "TARGET_SR = 16000\n",
    "\n",
    "# --- Helper functions ---\n",
    "def wavread(filename):\n",
    "    samplerate, wave_data = wav.read(filename)\n",
    "    data = np.asarray(wave_data, dtype=np.float32) / 32768.0\n",
    "    return data, samplerate\n",
    "\n",
    "def resample_aud(audio, sample_rate, target_sr=16000):\n",
    "    return librosa.core.resample(audio, orig_sr=sample_rate, target_sr=target_sr, res_type='kaiser_best')\n",
    "\n",
    "def read_wav_resample(filename):\n",
    "    audio, sample_rate = wavread(filename)\n",
    "    if sample_rate != TARGET_SR:\n",
    "        audio = resample_aud(audio, sample_rate, target_sr=TARGET_SR)\n",
    "    if audio.dtype != 'float32':\n",
    "        audio = np.array(audio, dtype=np.float32)\n",
    "    return audio\n",
    "\n",
    "def samples_to_embedding(audio, processor, model, sample_rate=16000):\n",
    "    if not tf.is_tensor(audio):\n",
    "        audio = tf.convert_to_tensor(audio)\n",
    "    if audio.shape.rank > 1:\n",
    "        audio = tf.squeeze(audio)\n",
    "    input_values = processor(audio.numpy(), sampling_rate=sample_rate, return_tensors='tf').input_values\n",
    "    hidden_states = model(input_values).last_hidden_state\n",
    "    return hidden_states.numpy()\n",
    "\n",
    "def get_prediction(filepath):\n",
    "    audio = read_wav_resample(filepath)\n",
    "    # cleaned_audio = nr.reduce_noise(y=audio, sr=TARGET_SR)  # noise reduc\n",
    "    emb = samples_to_embedding(audio, processor, hf_w2v2_model)\n",
    "    prediction = spice_w2v2_cls_model(emb)[0].numpy()  # Shape: [1, 5] — probabilities\n",
    "    predicted_class = int(np.argmax(prediction))       # Class 0 to 4\n",
    "    return predicted_class\n",
    "\n",
    "# --- Run inference over all files ---\n",
    "INPUT_CSV = \"C:/Users/YIDAN/Desktop/projects/dysarthria/dataset_youtube.csv\"\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "results = []\n",
    "\n",
    "# Paths\n",
    "OUTPUT_CSV = \"./spice_results_youtube_noiseReduce.csv\"\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    name = row['name']\n",
    "    path = row['path']\n",
    "    category = row['category']\n",
    "    \n",
    "    try:\n",
    "        pred = get_prediction(path)\n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"category\": category,\n",
    "            \"predicted_score\": pred\n",
    "        })\n",
    "        # print(f\"[✓] {name} → predicted: {pred} (true: {category})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error processing {name} at {path}: {e}\")\n",
    "\n",
    "# === Save results ===\n",
    "out_df = pd.DataFrame(results)\n",
    "out_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\n✅ Done! Results saved to: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366110f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvspice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
